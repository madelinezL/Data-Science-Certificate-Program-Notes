{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d793bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impoart Datasets\n",
    "import pandas as pd\n",
    "indiv=pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Individual Dataset\\CS703 Individual Dataset.csv')\n",
    "\n",
    "gt100=pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Global Weekly Top 100 Songs\\CS703 Global Weekly Top 100 Songs.csv')\n",
    "\n",
    "genl=pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Generalized Dataset\\CS703 Generalized Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6272ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "      <th>URI</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>...</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>popularity</th>\n",
       "      <th>scaled_key</th>\n",
       "      <th>scaled_loudness</th>\n",
       "      <th>scaled_tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1921</td>\n",
       "      <td>['Sergei Rachmaninoff', 'James Levine', 'Berli...</td>\n",
       "      <td>Piano Concerto No. 3 in D Minor, Op. 30: III. ...</td>\n",
       "      <td>4BJqT0PrAfrxzMOxytFOIz</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.211</td>\n",
       "      <td>10</td>\n",
       "      <td>-20.096</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>80.954</td>\n",
       "      <td>831667</td>\n",
       "      <td>4</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.624916</td>\n",
       "      <td>0.332450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1921</td>\n",
       "      <td>['Dennis Day']</td>\n",
       "      <td>Clancy Lowered the Boom</td>\n",
       "      <td>7xPhfUan2yNtyFG0cUWkt8</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.341</td>\n",
       "      <td>7</td>\n",
       "      <td>-12.441</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>60.936</td>\n",
       "      <td>180533</td>\n",
       "      <td>5</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.744797</td>\n",
       "      <td>0.250243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1921</td>\n",
       "      <td>['KHP Kridhamardawa Karaton Ngayogyakarta Hadi...</td>\n",
       "      <td>Gati Bali</td>\n",
       "      <td>1o6I8BglA6ylDMrIELygv1</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.166</td>\n",
       "      <td>3</td>\n",
       "      <td>-14.850</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.913000</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>110.339</td>\n",
       "      <td>500062</td>\n",
       "      <td>5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1921</td>\n",
       "      <td>['Frank Parker']</td>\n",
       "      <td>Danny Boy</td>\n",
       "      <td>3ftBPsC5vPBKxYSee08FDH</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.309</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.316</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>100.109</td>\n",
       "      <td>210000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.793736</td>\n",
       "      <td>0.411113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1921</td>\n",
       "      <td>['Phil Regan']</td>\n",
       "      <td>When Irish Eyes Are Smiling</td>\n",
       "      <td>4d6HGyGT8e121BsdKmw9v6</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.193</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.096</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>101.665</td>\n",
       "      <td>166693</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.781521</td>\n",
       "      <td>0.417503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                             artist  \\\n",
       "0  1921  ['Sergei Rachmaninoff', 'James Levine', 'Berli...   \n",
       "1  1921                                     ['Dennis Day']   \n",
       "2  1921  ['KHP Kridhamardawa Karaton Ngayogyakarta Hadi...   \n",
       "3  1921                                   ['Frank Parker']   \n",
       "4  1921                                     ['Phil Regan']   \n",
       "\n",
       "                                               track                     URI  \\\n",
       "0  Piano Concerto No. 3 in D Minor, Op. 30: III. ...  4BJqT0PrAfrxzMOxytFOIz   \n",
       "1                            Clancy Lowered the Boom  7xPhfUan2yNtyFG0cUWkt8   \n",
       "2                                          Gati Bali  1o6I8BglA6ylDMrIELygv1   \n",
       "3                                          Danny Boy  3ftBPsC5vPBKxYSee08FDH   \n",
       "4                        When Irish Eyes Are Smiling  4d6HGyGT8e121BsdKmw9v6   \n",
       "\n",
       "  release_date  danceability  energy  key  loudness  mode  ...  acousticness  \\\n",
       "0         1921         0.279   0.211   10   -20.096     1  ...         0.982   \n",
       "1         1921         0.819   0.341    7   -12.441     1  ...         0.732   \n",
       "2         1921         0.328   0.166    3   -14.850     1  ...         0.961   \n",
       "3         1921         0.275   0.309    5    -9.316     1  ...         0.967   \n",
       "4         1921         0.418   0.193    3   -10.096     1  ...         0.957   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  duration_ms  popularity  \\\n",
       "0          0.878000     0.665   0.0594   80.954       831667           4   \n",
       "1          0.000000     0.160   0.9630   60.936       180533           5   \n",
       "2          0.913000     0.101   0.0394  110.339       500062           5   \n",
       "3          0.000028     0.381   0.1650  100.109       210000           3   \n",
       "4          0.000002     0.229   0.2530  101.665       166693           2   \n",
       "\n",
       "   scaled_key  scaled_loudness  scaled_tempo  \n",
       "0    0.909091         0.624916      0.332450  \n",
       "1    0.636364         0.744797      0.250243  \n",
       "2    0.272727         0.707071      0.453125  \n",
       "3    0.454545         0.793736      0.411113  \n",
       "4    0.272727         0.781521      0.417503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale some of the attributes\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Scale the key, loudness, tempo attributes using min-max scaling in individual dataset\n",
    "key_scaler = MinMaxScaler()\n",
    "scaled_key = key_scaler.fit_transform(indiv[['key']])\n",
    "\n",
    "loudness_scaler = MinMaxScaler()\n",
    "scaled_loudness = loudness_scaler.fit_transform(indiv[['loudness']])\n",
    "\n",
    "tempo_scaler = MinMaxScaler()\n",
    "scaled_tempo = tempo_scaler.fit_transform(indiv[['tempo']])\n",
    "\n",
    "indiv['scaled_key']=scaled_key\n",
    "indiv['scaled_loudness']=scaled_loudness\n",
    "indiv['scaled_tempo']=scaled_tempo\n",
    "\n",
    "indiv.head()\n",
    "\n",
    "# Scale the key, loudness, tempo attributes using min-max scaling in global weekly top 100 songs dataset\n",
    "key_scaler = MinMaxScaler()\n",
    "scaled_key = key_scaler.fit_transform(gt100[['key']])\n",
    "\n",
    "loudness_scaler = MinMaxScaler()\n",
    "scaled_loudness = loudness_scaler.fit_transform(gt100[['loudness']])\n",
    "\n",
    "tempo_scaler = MinMaxScaler()\n",
    "scaled_tempo = tempo_scaler.fit_transform(gt100[['tempo']])\n",
    "\n",
    "gt100['scaled_key']=scaled_key\n",
    "gt100['scaled_loudness']=scaled_loudness\n",
    "gt100['scaled_tempo']=scaled_tempo\n",
    "\n",
    "gt100.head()\n",
    "\n",
    "# Scale the key, loudness, tempo attributes using min-max scaling in generalized dataset\n",
    "key_scaler = MinMaxScaler()\n",
    "scaled_key = key_scaler.fit_transform(genl[['key']])\n",
    "\n",
    "loudness_scaler = MinMaxScaler()\n",
    "scaled_loudness = loudness_scaler.fit_transform(genl[['loudness']])\n",
    "\n",
    "tempo_scaler = MinMaxScaler()\n",
    "scaled_tempo = tempo_scaler.fit_transform(genl[['tempo']])\n",
    "\n",
    "genl['scaled_key']=scaled_key\n",
    "genl['scaled_loudness']=scaled_loudness\n",
    "genl['scaled_tempo']=scaled_tempo\n",
    "\n",
    "genl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "234496f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       scaled_key  scaled_loudness  scaled_tempo\n",
      "count  945.000000       945.000000    945.000000\n",
      "mean     0.493891         0.851044      0.409108\n",
      "std      0.317217         0.080236      0.198653\n",
      "min      0.000000         0.000000      0.000000\n",
      "25%      0.181818         0.823773      0.247756\n",
      "50%      0.545455         0.863354      0.411446\n",
      "75%      0.727273         0.895020      0.539606\n",
      "max      1.000000         1.000000      1.000000\n",
      "       scaled_key  scaled_loudness  scaled_tempo\n",
      "count  100.000000       100.000000    100.000000\n",
      "mean     0.487273         0.588379      0.416351\n",
      "std      0.344908         0.165273      0.208721\n",
      "min      0.000000         0.000000      0.000000\n",
      "25%      0.090909         0.506426      0.240796\n",
      "50%      0.545455         0.622233      0.370492\n",
      "75%      0.818182         0.683993      0.537682\n",
      "max      1.000000         1.000000      1.000000\n",
      "          scaled_key  scaled_loudness   scaled_tempo\n",
      "count  170653.000000    170653.000000  170653.000000\n",
      "mean        0.472713         0.760035       0.479911\n",
      "std         0.319554         0.089233       0.126109\n",
      "min         0.000000         0.000000       0.000000\n",
      "25%         0.181818         0.710751       0.383648\n",
      "50%         0.454545         0.773941       0.471153\n",
      "75%         0.727273         0.827140       0.556604\n",
      "max         1.000000         1.000000       1.000000\n"
     ]
    }
   ],
   "source": [
    "print(indiv[['scaled_key', 'scaled_loudness', 'scaled_tempo']].describe())\n",
    "print(gt100[['scaled_key', 'scaled_loudness', 'scaled_tempo']].describe())\n",
    "print(genl[['scaled_key', 'scaled_loudness', 'scaled_tempo']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b02ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indiv Training data shape: (604, 19)\n",
      "Indiv Training msPlayed shape: (604,)\n",
      "Indiv Validation data shape: (152, 19)\n",
      "Indiv Validation msPlayed shape: (152,)\n",
      "Indiv Test data shape: (189, 19)\n",
      "Indiv Test msPlayed shape: (189,)\n"
     ]
    }
   ],
   "source": [
    "#Train/Validation/Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the indiv dataset into training and test sets (80% training data, 20% test data)\n",
    "indiv_train, indiv_test, msPlayed_train, msPlayed_test = train_test_split(indiv.drop('msPlayed', axis=1),\n",
    "                                                                          indiv['msPlayed'], \n",
    "                                                                          test_size=0.2, \n",
    "                                                                          random_state=69)\n",
    "\n",
    "# Split the training data further into training and validation sets (80% training data, 20% validation data)\n",
    "indiv_train, indiv_val, msPlayed_train, msPlayed_val = train_test_split(indiv_train, \n",
    "                                                                          msPlayed_train, \n",
    "                                                                          test_size=0.2, \n",
    "                                                                          random_state=69)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Indiv Training data shape:\", indiv_train.shape)\n",
    "print(\"Indiv Training msPlayed shape:\", msPlayed_train.shape)\n",
    "print(\"Indiv Validation data shape:\", indiv_val.shape)\n",
    "print(\"Indiv Validation msPlayed shape:\", msPlayed_val.shape)\n",
    "print(\"Indiv Test data shape:\", indiv_test.shape)\n",
    "print(\"Indiv Test msPlayed shape:\", msPlayed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e2dd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Audio Feature   Coefficient\n",
      "0       danceability  2.692141e+06\n",
      "1             energy  1.129856e+07\n",
      "2                key  2.390781e+05\n",
      "3           loudness -3.906484e+05\n",
      "4               mode -2.591887e+04\n",
      "5        speechiness -1.171750e+07\n",
      "6       acousticness -2.007160e+06\n",
      "7   instrumentalness -2.618687e+06\n",
      "8           liveness -1.588112e+06\n",
      "9            valence -5.277499e+06\n",
      "10             tempo  6.364634e+03\n",
      "Intercept: -3505086.6775206113\n",
      "RMSE (validation): 8343188.853441224\n",
      "RMSE (test): 5390453.982674943\n"
     ]
    }
   ],
   "source": [
    "#Content-based filtering methods - Supervised Learning \n",
    "#Data Modeling 1\n",
    "#Simple Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Include all audio features in the matrix X for the training set\n",
    "X_train = indiv_train[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_train = msPlayed_train\n",
    "\n",
    "# Include all audio features in the matrix X for the validation set\n",
    "X_valid = indiv_val[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_valid = msPlayed_val\n",
    "\n",
    "# Include all audio features in the matrix X for the test set\n",
    "X_test = indiv_test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_test = msPlayed_test\n",
    "\n",
    "# Convert X and y to numpy arrays for use with scikit-learn\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_valid = np.array(X_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Fit a linear regression model to the training set\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to predict the target variable for the validation set\n",
    "y_valid_pred = regressor.predict(X_valid)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Use the model to predict the target variable for the test set\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Print the model coefficients and RMSE on the validation and test sets\n",
    "audioFeature_names = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "coeffs = pd.DataFrame({'Audio Feature': audioFeature_names, 'Coefficient': regressor.coef_})\n",
    "print(coeffs)\n",
    "print('Intercept:', regressor.intercept_)\n",
    "print('RMSE (validation):', rmse_valid)\n",
    "print('RMSE (test):', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1658c8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Audio Feature   Coefficient\n",
      "0                         danceability  3.485046e+06\n",
      "1                               energy  1.125008e+07\n",
      "2                                  key  2.408934e+05\n",
      "3                             loudness -3.932826e+05\n",
      "4                                 mode -8.256091e+05\n",
      "5                          speechiness -1.160733e+07\n",
      "6                         acousticness -2.008240e+06\n",
      "7                     instrumentalness -2.235262e+06\n",
      "8                             liveness  1.973740e+06\n",
      "9                              valence -6.376743e+06\n",
      "10                               tempo  9.406975e+03\n",
      "11  danceability*energy*liveness*tempo -7.100421e+04\n",
      "12        instrumentalness*speechiness -5.811323e+06\n",
      "13                 mode*valence*energy  2.905286e+06\n",
      "Intercept: -3895055.9737705803\n",
      "RMSE (validation): 8329742.404600312\n",
      "RMSE (test): 5407794.5803636415\n"
     ]
    }
   ],
   "source": [
    "#Data Modeling 2\n",
    "#Linear Regression Model with Interactions\n",
    "#Danceability ~ Energy ~ Liveness ~ Tempo\n",
    "#Instrumentalness ~ Speechiness\n",
    "#Mode ~ Valence ~ Energy\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Include audio features and manually determined interaction terms in the matrix X for the training set\n",
    "indiv_train['danceability*energy*liveness*tempo'] = indiv_train['danceability'] * indiv_train['energy']* indiv_train['liveness']* indiv_train['tempo']\n",
    "indiv_train['instrumentalness*speechiness'] = indiv_train['instrumentalness'] * indiv_train['speechiness']\n",
    "indiv_train['mode*valence*energy'] = indiv_train['mode'] * indiv_train['valence'] * indiv_train['energy']\n",
    "X_train = indiv_train[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'danceability*energy*liveness*tempo', 'instrumentalness*speechiness', 'mode*valence*energy']]\n",
    "y_train = msPlayed_train\n",
    "\n",
    "# Include audio features and manually determined interaction terms in the matrix X for the validation set\n",
    "indiv_val['danceability*energy*liveness*tempo'] = indiv_val['danceability'] * indiv_val['energy']* indiv_val['liveness']* indiv_val['tempo']\n",
    "indiv_val['instrumentalness*speechiness'] = indiv_val['instrumentalness'] * indiv_val['speechiness']\n",
    "indiv_val['mode*valence*energy'] = indiv_val['mode'] * indiv_val['valence'] * indiv_val['energy']\n",
    "X_valid = indiv_val[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'danceability*energy*liveness*tempo', 'instrumentalness*speechiness', 'mode*valence*energy']]\n",
    "y_valid = msPlayed_val\n",
    "\n",
    "# Include audio features and manually determined interaction terms in the matrix X for the test set\n",
    "indiv_test['danceability*energy*liveness*tempo'] = indiv_test['danceability'] * indiv_test['energy']* indiv_test['liveness']* indiv_test['tempo']\n",
    "indiv_test['instrumentalness*speechiness'] = indiv_test['instrumentalness'] * indiv_test['speechiness']\n",
    "indiv_test['mode*valence*energy'] = indiv_test['mode'] * indiv_test['valence'] * indiv_test['energy']\n",
    "X_test = indiv_test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'danceability*energy*liveness*tempo', 'instrumentalness*speechiness', 'mode*valence*energy']]\n",
    "y_test = msPlayed_test\n",
    "\n",
    "# Fit a linear regression model to the training set\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to predict the target variable for the validation set\n",
    "y_valid_pred = regressor.predict(X_valid)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Use the model to predict the target variable for the test set\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Print the model coefficients and RMSE on the validation and test sets\n",
    "coeffs = pd.DataFrame({'Audio Feature': X_train.columns, 'Coefficient': regressor.coef_})\n",
    "print(coeffs)\n",
    "print('Intercept:', regressor.intercept_)\n",
    "print('RMSE (validation):', rmse_valid)\n",
    "print('RMSE (test):', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613bbc27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Audio Feature   Coefficient\n",
      "0                          1  1.313413e+19\n",
      "1               danceability  1.255435e+08\n",
      "2                     energy  4.658406e+07\n",
      "3                        key -1.905205e+07\n",
      "4                   loudness -2.531777e+07\n",
      "..                       ...           ...\n",
      "62  instrumentalness valence  6.292958e+07\n",
      "63    instrumentalness tempo -8.103084e+04\n",
      "64          liveness valence -2.696479e+07\n",
      "65            liveness tempo -1.316757e+06\n",
      "66             valence tempo  3.309241e+05\n",
      "\n",
      "[67 rows x 2 columns]\n",
      "Intercept: -1.313412704128008e+19\n",
      "RMSE (validation): 28940654.211860877\n",
      "RMSE (test): 30359388.635418043\n"
     ]
    }
   ],
   "source": [
    "#Data Modeling 3\n",
    "#Stepwise Model\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Include all audio features in the matrix X for the training set\n",
    "X_train = indiv_train[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_train = msPlayed_train\n",
    "\n",
    "# Include all audio features in the matrix X for the validation set\n",
    "X_valid = indiv_val[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_valid = msPlayed_val\n",
    "\n",
    "# Include all audio features in the matrix X for the test set\n",
    "X_test = indiv_test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_test = msPlayed_test\n",
    "\n",
    "# Create interaction terms for the training set\n",
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "X_train_interact = poly.fit_transform(X_train)\n",
    "\n",
    "# Create interaction terms for the validation set\n",
    "X_valid_interact = poly.transform(X_valid)\n",
    "\n",
    "# Create interaction terms for the test set\n",
    "X_test_interact = poly.transform(X_test)\n",
    "\n",
    "# Fit a linear regression model to the training set\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_interact, y_train)\n",
    "\n",
    "# Use the model to predict the target variable for the validation set\n",
    "y_valid_pred = regressor.predict(X_valid_interact)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Use the model to predict the target variable for the test set\n",
    "y_test_pred = regressor.predict(X_test_interact)\n",
    "\n",
    "# Calculate the RSME between the predicted and actual values on the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Print the model coefficients and RMSE on the validation and test sets\n",
    "audioFeature_names = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "audioFeature_interact_names = poly.get_feature_names_out(audioFeature_names)\n",
    "coeffs = pd.DataFrame({'Audio Feature': audioFeature_interact_names, 'Coefficient': regressor.coef_})\n",
    "print(coeffs)\n",
    "print('Intercept:', regressor.intercept_)\n",
    "print('RMSE (validation):', rmse_valid)\n",
    "print('RMSE (test):', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8c7ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Audio Feature  Importance\n",
      "0       danceability    0.044955\n",
      "1             energy    0.090306\n",
      "2                key    0.038821\n",
      "3           loudness    0.060877\n",
      "4               mode    0.026226\n",
      "5        speechiness    0.088814\n",
      "6       acousticness    0.323193\n",
      "7   instrumentalness    0.018705\n",
      "8           liveness    0.018914\n",
      "9            valence    0.193849\n",
      "10             tempo    0.095341\n",
      "RMSE (validation): 13798540.815978158\n",
      "RMSE (test): 15059149.18537464\n"
     ]
    }
   ],
   "source": [
    "#Data Modeling 4\n",
    "#Decision Tree Model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Include audio features in the matrix X for the training set\n",
    "X_train = indiv_train[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_train = msPlayed_train\n",
    "\n",
    "# Include audio features in the matrix X for the validation set\n",
    "X_valid = indiv_val[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_valid = msPlayed_val\n",
    "\n",
    "# Include audio features in the matrix X for the test set\n",
    "X_test = indiv_test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_test = msPlayed_test\n",
    "\n",
    "# Fit a decision tree model to the training set\n",
    "tree = DecisionTreeRegressor(max_depth=15, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to predict the target variable for the validation set\n",
    "y_valid_pred = tree.predict(X_valid)\n",
    "\n",
    "# Calculate RMSE between the predicted and actual values on the validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Use the model to predict the target variable for the test set\n",
    "y_test_pred = tree.predict(X_test)\n",
    "\n",
    "# Calculate RMSE between the predicted and actual values on the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Print the feature importances and RMSE on the validation and validation and test sets\n",
    "importances = tree.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "importances_df = pd.DataFrame({'Audio Feature': feature_names, 'Importance': importances})\n",
    "print(importances_df)\n",
    "print('RMSE (validation):', rmse_valid)\n",
    "print('RMSE (test):', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25fa3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Modeling 5\n",
    "#Random Forest Model\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Include audio features in the matrix X for the training set\n",
    "X_train = indiv_train[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_train = msPlayed_train\n",
    "\n",
    "# Include audio features in the matrix X for the validation set\n",
    "X_valid = indiv_val[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_valid = msPlayed_val\n",
    "\n",
    "# Include audio features in the matrix X for the test set\n",
    "X_test = indiv_test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_test = msPlayed_test\n",
    "\n",
    "# Fit a random forest model to the training set\n",
    "forest = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=0) #n_estimators is a parameter that represents the number of decision trees #random_state is an arbitrarily number\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to predict the target variable for the validation set\n",
    "y_valid_pred = tree.predict(X_valid)\n",
    "\n",
    "# Calculate the mean squared error between the predicted and actual values on the validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Use the model to predict the target variable for the test set\n",
    "y_test_pred = forest.predict(X_test)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Print the feature importances and RMSE on the validation and test sets\n",
    "importances = forest.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "importances_df = pd.DataFrame({'Audio Feature': feature_names, 'Importance': importances})\n",
    "print(importances_df)\n",
    "print('RMSE (validation):', rmse_valid)\n",
    "print('RMSE (test):', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ee0fbb5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: c:\\Users\\madlin\\AppData\\Local\\Temp\\tmp7o1urycd\n",
      "Requirement already satisfied: setuptools in c:\\users\\madlin\\anaconda3\\lib\\site-packages (63.4.1)\n",
      "Requirement already satisfied: pip in c:\\users\\madlin\\anaconda3\\lib\\site-packages (22.2.2)\n"
     ]
    }
   ],
   "source": [
    "!python -m ensurepip --default-pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9385aa0e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install kera\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2367fe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 16ms/step - loss: 126341882052608.0000 - val_loss: 93538423406592.0000\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126341764612096.0000 - val_loss: 93538297577472.0000\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126341638782976.0000 - val_loss: 93538171748352.0000\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 126341529731072.0000 - val_loss: 93538054307840.0000\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126341395513344.0000 - val_loss: 93537920090112.0000\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126341244518400.0000 - val_loss: 93537743929344.0000\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126341059969024.0000 - val_loss: 93537567768576.0000\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 126340858642432.0000 - val_loss: 93537341276160.0000\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126340640538624.0000 - val_loss: 93537064452096.0000\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126340346937344.0000 - val_loss: 93536762462208.0000\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126340019781632.0000 - val_loss: 93536376586240.0000\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126339617128448.0000 - val_loss: 93535906824192.0000\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126339097034752.0000 - val_loss: 93535344787456.0000\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126338467889152.0000 - val_loss: 93534614978560.0000\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126337687748608.0000 - val_loss: 93533767729152.0000\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126336806944768.0000 - val_loss: 93532777873408.0000\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126335766757376.0000 - val_loss: 93531704131584.0000\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126334642683904.0000 - val_loss: 93530496172032.0000\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126333417947136.0000 - val_loss: 93529128828928.0000\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126331966717952.0000 - val_loss: 93527702765568.0000\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126330473545728.0000 - val_loss: 93525991489536.0000\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126328728715264.0000 - val_loss: 93524145995776.0000\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126326765780992.0000 - val_loss: 93522157895680.0000\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126324760903680.0000 - val_loss: 93519842639872.0000\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126322412093440.0000 - val_loss: 93517477052416.0000\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 126319954231296.0000 - val_loss: 93514868195328.0000\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126317303431168.0000 - val_loss: 93512016068608.0000\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126314392584192.0000 - val_loss: 93508971003904.0000\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126311280410624.0000 - val_loss: 93505707835392.0000\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 126307933356032.0000 - val_loss: 93502201397248.0000\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126304250757120.0000 - val_loss: 93498686570496.0000\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126300568158208.0000 - val_loss: 93494542598144.0000\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126296474517504.0000 - val_loss: 93490289573888.0000\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126292120829952.0000 - val_loss: 93485893943296.0000\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126287792308224.0000 - val_loss: 93480894332928.0000\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126282801086464.0000 - val_loss: 93476079271936.0000\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126277910528000.0000 - val_loss: 93470718951424.0000\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126272466321408.0000 - val_loss: 93465400573952.0000\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126267248607232.0000 - val_loss: 93459268501504.0000\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126261041037312.0000 - val_loss: 93453539082240.0000\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126255143845888.0000 - val_loss: 93447146962944.0000\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126248802058240.0000 - val_loss: 93440503185408.0000\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126242099560448.0000 - val_loss: 93433708412928.0000\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126235405451264.0000 - val_loss: 93426276106240.0000\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126227864092672.0000 - val_loss: 93419087069184.0000\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126220524060672.0000 - val_loss: 93411369549824.0000\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126212546494464.0000 - val_loss: 93403719139328.0000\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126204929638400.0000 - val_loss: 93394869157888.0000\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126196155154432.0000 - val_loss: 93386379886592.0000\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126187732992000.0000 - val_loss: 93377135640576.0000\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126178530689024.0000 - val_loss: 93367958503424.0000\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126169143836672.0000 - val_loss: 93358487764992.0000\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126159597600768.0000 - val_loss: 93348513710080.0000\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126149506105344.0000 - val_loss: 93338397048832.0000\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126139179728896.0000 - val_loss: 93327819014144.0000\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126128954015744.0000 - val_loss: 93316058185728.0000\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126117746835456.0000 - val_loss: 93304590958592.0000\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126105927286784.0000 - val_loss: 93293627047936.0000\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 126094694940672.0000 - val_loss: 93281404846080.0000\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126082590179328.0000 - val_loss: 93268956151808.0000\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126070200205312.0000 - val_loss: 93256197079040.0000\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126057432743936.0000 - val_loss: 93243161182208.0000\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126044203909120.0000 - val_loss: 93229890404352.0000\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126030580809728.0000 - val_loss: 93216527351808.0000\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 126016898990080.0000 - val_loss: 93202191220736.0000\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 126002931957760.0000 - val_loss: 93187083337728.0000\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 125987958292480.0000 - val_loss: 93172252278784.0000\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125973068513280.0000 - val_loss: 93156783685632.0000\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 125957541199872.0000 - val_loss: 93141197651968.0000\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 125942181658624.0000 - val_loss: 93124680482816.0000\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125925798707200.0000 - val_loss: 93108238811136.0000\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125909482864640.0000 - val_loss: 93091176382464.0000\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125892445601792.0000 - val_loss: 93074357223424.0000\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125875467059200.0000 - val_loss: 93056883752960.0000\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125858387853312.0000 - val_loss: 93038487535616.0000\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125839924527104.0000 - val_loss: 93020930179072.0000\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 125822149066752.0000 - val_loss: 93001938370560.0000\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 125803501191168.0000 - val_loss: 92982854287360.0000\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125784249335808.0000 - val_loss: 92964047028224.0000\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125765475631104.0000 - val_loss: 92943897591808.0000\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125745678516224.0000 - val_loss: 92923639103488.0000\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125725654908928.0000 - val_loss: 92903070236672.0000\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125704649834496.0000 - val_loss: 92883088572416.0000\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125684349403136.0000 - val_loss: 92861462740992.0000\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125663520489472.0000 - val_loss: 92838603784192.0000\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125641164849152.0000 - val_loss: 92816961175552.0000\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125619572572160.0000 - val_loss: 92794236436480.0000\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125597468590080.0000 - val_loss: 92770999992320.0000\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 125574408306688.0000 - val_loss: 92748015206400.0000\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125551809396736.0000 - val_loss: 92723897958400.0000\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125527130112000.0000 - val_loss: 92701726867456.0000\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125504589922304.0000 - val_loss: 92676594597888.0000\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125479927414784.0000 - val_loss: 92651999199232.0000\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125456263151616.0000 - val_loss: 92625801576448.0000\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125430350741504.0000 - val_loss: 92601038405632.0000\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125405495296000.0000 - val_loss: 92575084052480.0000\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125379322839040.0000 - val_loss: 92549482020864.0000\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125353183936512.0000 - val_loss: 92523317952512.0000\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125326835318784.0000 - val_loss: 92496004644864.0000\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 125300276985856.0000 - val_loss: 92467466600448.0000\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "RMSE (validation): 28940654.211860877\n",
      "RMSE (test): 6122879.076282405\n"
     ]
    }
   ],
   "source": [
    "#Data Modeling 6\n",
    "#Neural Network Model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Include audio features in the matrix X for the training set\n",
    "X_train = indiv_train[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_train = msPlayed_train\n",
    "\n",
    "# Include audio features in the matrix X for the validation set\n",
    "X_valid = indiv_val[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_valid = msPlayed_val\n",
    "\n",
    "# Include audio features in the matrix X for the test set\n",
    "X_test = indiv_test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y_test = msPlayed_test\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=11, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Train the model on the training set\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Use the model to predict the target variable for the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Print the RMSE on the validation and test sets\n",
    "print('RMSE (validation):', rmse_valid)\n",
    "print('RMSE (test):', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc02e544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
      "468         0.534   0.325   11    -7.612     0       0.0362         0.757   \n",
      "\n",
      "     instrumentalness  liveness  valence   tempo  \n",
      "468               0.0    0.0699    0.394  148.12  \n"
     ]
    }
   ],
   "source": [
    "#Collaborative filtering method - Unsupervised Learning\n",
    "#Similarity Metric 1\n",
    "#Euclidean Distance\n",
    "\n",
    "# Input the name of the track I like\n",
    "track = 'Soft'\n",
    "\n",
    "# Filter the DataFrame based on the track name\n",
    "filtered_indiv = indiv[indiv['track'] == 'Soft']\n",
    "\n",
    "# Display the audio features for the specified track\n",
    "print(filtered_indiv[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b4b8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar tracks to \"Soft\" by Soft are:\n",
      "Hong Kong by ['Gorillaz']:\n",
      "danceability: 0.513\n",
      "energy: 0.582\n",
      "key: 11\n",
      "loudness: -7.394\n",
      "mode: 0\n",
      "speechiness: 0.0285\n",
      "acousticness: 0.712\n",
      "instrumentalness: 0.0369\n",
      "liveness: 0.0771\n",
      "valence: 0.241\n",
      "tempo: 148.128\n",
      "\n",
      "Mongoloid - 2009 Remaster by ['DEVO']:\n",
      "danceability: 0.573\n",
      "energy: 0.616\n",
      "key: 11\n",
      "loudness: -7.806\n",
      "mode: 0\n",
      "speechiness: 0.0445\n",
      "acousticness: 0.0743\n",
      "instrumentalness: 0.0437\n",
      "liveness: 0.0996\n",
      "valence: 0.588\n",
      "tempo: 148.148\n",
      "\n",
      "Bad Habits - uncut by ['Maxwell']:\n",
      "danceability: 0.661\n",
      "energy: 0.67\n",
      "key: 11\n",
      "loudness: -7.645\n",
      "mode: 0\n",
      "speechiness: 0.258\n",
      "acousticness: 0.0873\n",
      "instrumentalness: 2.01e-06\n",
      "liveness: 0.0794\n",
      "valence: 0.661\n",
      "tempo: 148.02\n",
      "\n",
      "Stepping Into Tomorrow by ['Donald Byrd']:\n",
      "danceability: 0.675\n",
      "energy: 0.919\n",
      "key: 11\n",
      "loudness: -7.772\n",
      "mode: 0\n",
      "speechiness: 0.0406\n",
      "acousticness: 0.247\n",
      "instrumentalness: 0.0658\n",
      "liveness: 0.299\n",
      "valence: 0.872\n",
      "tempo: 148.241\n",
      "\n",
      "This Town (feat. Sasha Sloan) by ['Kygo', 'Sasha Sloan']:\n",
      "danceability: 0.736\n",
      "energy: 0.449\n",
      "key: 10\n",
      "loudness: -7.956\n",
      "mode: 0\n",
      "speechiness: 0.0633\n",
      "acousticness: 0.506\n",
      "instrumentalness: 6.63e-05\n",
      "liveness: 0.117\n",
      "valence: 0.487\n",
      "tempo: 147.971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the individual dataset and filter for the desired track\n",
    "track = 'Soft'\n",
    "indiv = pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Individual Dataset\\CS703 Individual Dataset.csv')\n",
    "track_row = indiv.loc[indiv['track'] == track]\n",
    "track_features = track_row.iloc[:, 4:15].values[0]\n",
    "track_artist = track_row.iloc[0, 2]\n",
    "\n",
    "# Load the generalized dataset and extract the relevant audio features\n",
    "genl = pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Generalized Dataset\\CS703 Generalized Dataset.csv')\n",
    "genl_features = genl.iloc[:, 5:16].values\n",
    "genl_artists = genl.iloc[:, 1].values\n",
    "\n",
    "# Calculate the Euclidean distances between the track features and all other tracks\n",
    "distances = np.sqrt(np.sum(np.square(genl_features - track_features), axis=1))\n",
    "\n",
    "# Find the indices of 5 tracks with the smallest distance (i.e., the 5 most similar tracks)\n",
    "most_similar_indices = np.argsort(distances)[:5]\n",
    "\n",
    "# Extract the information of the most similar tracks\n",
    "most_similar_features = genl.iloc[most_similar_indices, 5:16]\n",
    "most_similar_track_names = genl.iloc[most_similar_indices, 2]\n",
    "most_similar_artists = genl.iloc[most_similar_indices, 1]\n",
    "\n",
    "# Get the names of the audio feature coefficients\n",
    "feature_names = list(genl.columns[5:16])\n",
    "\n",
    "# Display the most similar tracks and their features\n",
    "print(f'The 5 most similar tracks to \"{track}\" by {track_artist} are:')\n",
    "for i in range(5):\n",
    "    print(f'{most_similar_track_names.iloc[i]} by {most_similar_artists.iloc[i]}:')\n",
    "    for j in range(len(feature_names)):\n",
    "        print(f'{feature_names[j]}: {most_similar_features.iloc[i, j]}')\n",
    "    print()  # print an empty line for spacing between each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "112cf71e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 217. GiB for an array with shape (170654, 170654) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12584\\663385147.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Calculate the Pearson correlation coefficients between the track features and all other tracks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mcorrelations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenl_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Get the column index of the track features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcorrcoef\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcorrcoef\u001b[1;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[0;32m   2681\u001b[0m         warnings.warn('bias and ddof have no effect and are deprecated',\n\u001b[0;32m   2682\u001b[0m                       DeprecationWarning, stacklevel=3)\n\u001b[1;32m-> 2683\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrowvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2684\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2685\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcov\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2539\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2540\u001b[0m         \u001b[0mX_T\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2541\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_T\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2542\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_divide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2543\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 217. GiB for an array with shape (170654, 170654) and data type float64"
     ]
    }
   ],
   "source": [
    "# Load the individual dataset and filter for the desired track\n",
    "track = 'Soft'\n",
    "indiv = pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Individual Dataset\\CS703 Individual Dataset.csv')\n",
    "track_features = indiv.loc[indiv['track'] == track].iloc[:, 4:15].values[0]\n",
    "\n",
    "# Load the generalized dataset and extract the relevant audio features\n",
    "genl = pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Generalized Dataset\\CS703 Generalized Dataset.csv')\n",
    "genl_features = genl.iloc[:, 5:16].values\n",
    "\n",
    "# Calculate the Pearson correlation coefficients between the track features and all other tracks\n",
    "correlations = np.corrcoef(genl_features, track_features)\n",
    "\n",
    "# Get the column index of the track features\n",
    "track_index = indiv.columns.get_loc('track') + 1\n",
    "\n",
    "# Find the indices of 5 tracks with the highest correlation (i.e., the 5 most similar tracks)\n",
    "most_similar_indices = np.argsort(correlations[:, track_index])[::-1][:5]\n",
    "\n",
    "# Extract the information of the most similar tracks\n",
    "most_similar_features = genl.iloc[most_similar_indices, 5:16]\n",
    "most_similar_track_names = genl.iloc[most_similar_indices, [1, 2]]\n",
    "\n",
    "# Rename the columns to include artist and track names\n",
    "most_similar_track_names.columns = ['artist', 'track']\n",
    "\n",
    "# Get the names of the audio feature coefficients\n",
    "feature_names = list(genl.columns[5:16])\n",
    "\n",
    "# Create a comparison table of the most similar tracks and the original track\n",
    "table = pd.concat([most_similar_track_names.reset_index(drop=True), most_similar_features.reset_index(drop=True).T, track_features.reshape(-1,1)], axis=1)\n",
    "table.columns = ['artist', 'track'] + most_similar_track_names.tolist() + [track]\n",
    "\n",
    "# Display the most similar tracks and their features\n",
    "print(f'The 5 most similar tracks to \"{track}\" are:')\n",
    "print(table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f46396e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar tracks to \"Soft\" are:\n",
      "Citgo by ['Chief Keef']:\n",
      "danceability: 0.675\n",
      "energy: 0.486\n",
      "key: 10\n",
      "loudness: -7.397\n",
      "mode: 0\n",
      "speechiness: 0.0482\n",
      "acousticness: 0.595\n",
      "instrumentalness: 0.0\n",
      "liveness: 0.1\n",
      "valence: 0.414\n",
      "tempo: 140.073\n",
      "\n",
      "Hello, Dolly! - From the Musical Production, \"Hello Dolly\" by ['Paul Anka']:\n",
      "danceability: 0.372\n",
      "energy: 0.547\n",
      "key: 11\n",
      "loudness: -7.646\n",
      "mode: 0\n",
      "speechiness: 0.0925\n",
      "acousticness: 0.72\n",
      "instrumentalness: 0.0\n",
      "liveness: 0.502\n",
      "valence: 0.552\n",
      "tempo: 149.514\n",
      "\n",
      "Love, Life And Money by ['Little Willie John']:\n",
      "danceability: 0.446\n",
      "energy: 0.499\n",
      "key: 10\n",
      "loudness: -7.299\n",
      "mode: 0\n",
      "speechiness: 0.0333\n",
      "acousticness: 0.886\n",
      "instrumentalness: 1.5e-05\n",
      "liveness: 0.205\n",
      "valence: 0.567\n",
      "tempo: 137.922\n",
      "\n",
      "Tadow by ['Masego', 'FKJ']:\n",
      "danceability: 0.704\n",
      "energy: 0.487\n",
      "key: 9\n",
      "loudness: -6.407\n",
      "mode: 0\n",
      "speechiness: 0.0604\n",
      "acousticness: 0.669\n",
      "instrumentalness: 8.64e-05\n",
      "liveness: 0.111\n",
      "valence: 0.313\n",
      "tempo: 121.726\n",
      "\n",
      "Good Vibrations - Remastered by ['The Beach Boys']:\n",
      "danceability: 0.403\n",
      "energy: 0.495\n",
      "key: 10\n",
      "loudness: -6.888\n",
      "mode: 0\n",
      "speechiness: 0.0312\n",
      "acousticness: 0.387\n",
      "instrumentalness: 8.03e-06\n",
      "liveness: 0.147\n",
      "valence: 0.38\n",
      "tempo: 132.912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Similarity Metric 3\n",
    "#Cosine Similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the individual dataset and filter for the desired track\n",
    "track = 'Soft'\n",
    "indiv = pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Individual Dataset\\CS703 Individual Dataset.csv')\n",
    "track_features = indiv.loc[indiv['track'] == track].iloc[:, 4:15].values[0]\n",
    "\n",
    "# Load the generalized dataset and extract the relevant audio features and artist names\n",
    "genl = pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Generalized Dataset\\CS703 Generalized Dataset.csv')\n",
    "genl_features = genl.iloc[:, 5:16].values\n",
    "genl_artists = genl.iloc[:, 1].values\n",
    "\n",
    "# Calculate the cosine similarities between the track features and all other tracks\n",
    "similarities = cosine_similarity(track_features.reshape(1, -1), genl_features)\n",
    "\n",
    "# Find the indices of 5 tracks with the highest cosine similarity\n",
    "most_similar_indices = np.argsort(similarities[0])[-6:-1]\n",
    "\n",
    "# Extract the information of the most similar tracks\n",
    "most_similar_features = genl.iloc[most_similar_indices, 5:16]\n",
    "most_similar_track_names = genl.iloc[most_similar_indices, 2]\n",
    "most_similar_artists = genl_artists[most_similar_indices]\n",
    "\n",
    "# Get the names of the audio feature coefficients\n",
    "feature_names = list(genl.columns[5:16])\n",
    "\n",
    "# Display the most similar tracks and their features\n",
    "print(f'The 5 most similar tracks to \"{track}\" are:')\n",
    "for i in range(5):\n",
    "    print(f'{most_similar_track_names.iloc[i]} by {most_similar_artists[i]}:')\n",
    "    for j in range(len(feature_names)):\n",
    "        print(f'{feature_names[j]}: {most_similar_features.iloc[i, j]}')\n",
    "    print()  # print an empty line for spacing between each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "756a127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Audio Feature   Coefficient\n",
      "0                   danceability  4.419394e+06\n",
      "1                         energy  9.512113e+06\n",
      "2                            key  3.014784e+05\n",
      "3                       loudness -2.532981e+05\n",
      "4                           mode -1.470128e+06\n",
      "5                    speechiness -9.648437e+06\n",
      "6                   acousticness -9.186839e+05\n",
      "7               instrumentalness  1.833977e+06\n",
      "8                       liveness  1.081713e+06\n",
      "9                        valence -7.086316e+06\n",
      "10                         tempo  9.581889e+03\n",
      "11  instrumentalness*speechiness -6.808614e+07\n",
      "12           mode*valence*energy  3.305357e+06\n",
      "Intercept: -3051501.7424576553\n",
      "RMSE (validation): 7477293.322066186\n",
      "RMSE (test): 5144825.893391904\n"
     ]
    }
   ],
   "source": [
    "#Revised Parameter Settings\n",
    "#Revised Regression Model 1\n",
    "\n",
    "#Instrumentalness ~ Speechiness\n",
    "#Mode ~ Valence ~ Energy\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Include audio features and manually determined interaction terms in the matrix X for the training set\n",
    "indiv_train['instrumentalness*speechiness'] = indiv_train['instrumentalness'] * indiv_train['speechiness']\n",
    "indiv_train['mode*valence*energy'] = indiv_train['mode'] * indiv_train['valence'] * indiv_train['energy']\n",
    "X_train = indiv_train[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'instrumentalness*speechiness', 'mode*valence*energy']]\n",
    "y_train = msPlayed_train\n",
    "\n",
    "# Include audio features and manually determined interaction terms in the matrix X for the validation set\n",
    "indiv_val['instrumentalness*speechiness'] = indiv_val['instrumentalness'] * indiv_val['speechiness']\n",
    "indiv_val['mode*valence*energy'] = indiv_val['mode'] * indiv_val['valence'] * indiv_val['energy']\n",
    "X_valid = indiv_val[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'instrumentalness*speechiness', 'mode*valence*energy']]\n",
    "y_valid = msPlayed_val\n",
    "\n",
    "# Include audio features and manually determined interaction terms in the matrix X for the test set\n",
    "indiv_test['instrumentalness*speechiness'] = indiv_test['instrumentalness'] * indiv_test['speechiness']\n",
    "indiv_test['mode*valence*energy'] = indiv_test['mode'] * indiv_test['valence'] * indiv_test['energy']\n",
    "X_test = indiv_test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'instrumentalness*speechiness', 'mode*valence*energy']]\n",
    "y_test = msPlayed_test\n",
    "\n",
    "# Fit a linear regression model to the training set\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to predict the target variable for the validation set\n",
    "y_valid_pred = regressor.predict(X_valid)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Use the model to predict the target variable for the test set\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Print the model coefficients and RMSE on the validation and test sets\n",
    "coeffs = pd.DataFrame({'Audio Feature': X_train.columns, 'Coefficient': regressor.coef_})\n",
    "print(coeffs)\n",
    "print('Intercept:', regressor.intercept_)\n",
    "print('RMSE (validation):', rmse_valid)\n",
    "print('RMSE (test):', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6110e45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Audio Feature   Coefficient\n",
      "0                   danceability  1.019582e+07\n",
      "1                         energy  1.810585e+07\n",
      "2                            key  3.020612e+05\n",
      "3                       loudness -2.809619e+05\n",
      "4                           mode -4.911389e+05\n",
      "5                    speechiness -1.007410e+07\n",
      "6                   acousticness -8.785976e+05\n",
      "7               instrumentalness  1.639679e+06\n",
      "8                       liveness  7.512530e+05\n",
      "9                        valence -5.893945e+06\n",
      "10                         tempo  9.548918e+03\n",
      "11           danceability*energy -1.099299e+07\n",
      "12  instrumentalness*speechiness -6.479854e+07\n",
      "Intercept: -8364076.85887859\n",
      "RMSE (validation): 17060056.796461314\n",
      "RMSE (test): 15518902.639484894\n"
     ]
    }
   ],
   "source": [
    "#Revised Parameter Settings\n",
    "#Revised Regression Model 2\n",
    "\n",
    "#Danceability ~ Energy \n",
    "#Instrumentalness ~ Speechiness\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Include audio features and manually determined interaction terms in the matrix X for the training set\n",
    "indiv_train['danceability*energy'] = indiv_train['danceability'] * indiv_train['energy']\n",
    "indiv_train['instrumentalness*speechiness'] = indiv_train['instrumentalness'] * indiv_train['speechiness']\n",
    "X_train = indiv_train[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'danceability*energy','instrumentalness*speechiness']]\n",
    "y_train = msPlayed_train\n",
    "\n",
    "# Include audio features and manually determined interaction terms in the matrix X for the validation set\n",
    "indiv_val['danceability*energy'] = indiv_val['danceability'] * indiv_val['energy']\n",
    "indiv_val['instrumentalness*speechiness'] = indiv_val['mode'] * indiv_val['valence'] * indiv_val['energy']\n",
    "X_valid = indiv_val[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'danceability*energy','instrumentalness*speechiness']]\n",
    "y_valid = msPlayed_val\n",
    "\n",
    "# Include audio features and manually determined interaction terms in the matrix X for the test set\n",
    "indiv_test['danceability*energy'] = indiv_test['danceability'] * indiv_test['energy']\n",
    "indiv_test['instrumentalness*speechiness'] = indiv_test['mode'] * indiv_test['valence'] * indiv_test['energy']\n",
    "X_test = indiv_test[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'danceability*energy','instrumentalness*speechiness']]\n",
    "y_test = msPlayed_test\n",
    "\n",
    "# Fit a linear regression model to the training set\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to predict the target variable for the validation set\n",
    "y_valid_pred = regressor.predict(X_valid)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the validation set\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "# Use the model to predict the target variable for the test set\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate the RMSE between the predicted and actual values on the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "# Print the model coefficients and RMSE on the validation and test sets\n",
    "coeffs = pd.DataFrame({'Audio Feature': X_train.columns, 'Coefficient': regressor.coef_})\n",
    "print(coeffs)\n",
    "print('Intercept:', regressor.intercept_)\n",
    "print('RMSE (validation):', rmse_valid)\n",
    "print('RMSE (test):', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f22e0b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar tracks to \"Soft\" by Soft are:\n",
      "Hong Kong by ['Gorillaz']:\n",
      "danceability: 0.513\n",
      "energy: 0.582\n",
      "key: 11\n",
      "loudness: -7.394\n",
      "mode: 0\n",
      "speechiness: 0.0285\n",
      "acousticness: 0.712\n",
      "instrumentalness: 0.0369\n",
      "liveness: 0.0771\n",
      "valence: 0.241\n",
      "tempo: 148.128\n",
      "\n",
      "Mongoloid - 2009 Remaster by ['DEVO']:\n",
      "danceability: 0.573\n",
      "energy: 0.616\n",
      "key: 11\n",
      "loudness: -7.806\n",
      "mode: 0\n",
      "speechiness: 0.0445\n",
      "acousticness: 0.0743\n",
      "instrumentalness: 0.0437\n",
      "liveness: 0.0996\n",
      "valence: 0.588\n",
      "tempo: 148.148\n",
      "\n",
      "Bad Habits - uncut by ['Maxwell']:\n",
      "danceability: 0.661\n",
      "energy: 0.67\n",
      "key: 11\n",
      "loudness: -7.645\n",
      "mode: 0\n",
      "speechiness: 0.258\n",
      "acousticness: 0.0873\n",
      "instrumentalness: 2.01e-06\n",
      "liveness: 0.0794\n",
      "valence: 0.661\n",
      "tempo: 148.02\n",
      "\n",
      "When I Say I Do by ['Matthew West']:\n",
      "danceability: 0.478\n",
      "energy: 0.433\n",
      "key: 11\n",
      "loudness: -7.16\n",
      "mode: 1\n",
      "speechiness: 0.0328\n",
      "acousticness: 0.77\n",
      "instrumentalness: 0.0\n",
      "liveness: 0.219\n",
      "valence: 0.31\n",
      "tempo: 147.919\n",
      "\n",
      "This Town (feat. Sasha Sloan) by ['Kygo', 'Sasha Sloan']:\n",
      "danceability: 0.736\n",
      "energy: 0.449\n",
      "key: 10\n",
      "loudness: -7.956\n",
      "mode: 0\n",
      "speechiness: 0.0633\n",
      "acousticness: 0.506\n",
      "instrumentalness: 6.63e-05\n",
      "liveness: 0.117\n",
      "valence: 0.487\n",
      "tempo: 147.971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Revised Parameter Settings\n",
    "#Revised Regression Model 3\n",
    "\n",
    "# Load the individual dataset and filter for the desired track\n",
    "track = 'Soft'\n",
    "indiv = pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Individual Dataset\\CS703 Individual Dataset.csv')\n",
    "track_row = indiv.loc[indiv['track'] == track]\n",
    "track_features = track_row.iloc[:, 4:15].values[0]\n",
    "track_artist = track_row.iloc[0, 2]\n",
    "\n",
    "# Load the generalized dataset and extract the relevant audio features\n",
    "genl = pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Applied DS Project\\Data\\Generalized Dataset\\CS703 Generalized Dataset.csv')\n",
    "genl_features = genl.iloc[:, 5:16].values\n",
    "genl_artists = genl.iloc[:, 1].values\n",
    "\n",
    "# Calculate the Manhattan distances between the track features and all other tracks\n",
    "distances = np.sum(np.abs(genl_features - track_features), axis=1)\n",
    "\n",
    "# Find the indices of 5 tracks with the smallest distance (i.e., the 5 most similar tracks)\n",
    "most_similar_indices = np.argsort(distances)[:5]\n",
    "\n",
    "# Extract the information of the most similar tracks\n",
    "most_similar_features = genl.iloc[most_similar_indices, 5:16]\n",
    "most_similar_track_names = genl.iloc[most_similar_indices, 2]\n",
    "most_similar_artists = genl.iloc[most_similar_indices, 1]\n",
    "\n",
    "# Get the names of the audio feature coefficients\n",
    "feature_names = list(genl.columns[5:16])\n",
    "\n",
    "# Display the most similar tracks and their features\n",
    "print(f'The 5 most similar tracks to \"{track}\" by {track_artist} are:')\n",
    "for i in range(5):\n",
    "    print(f'{most_similar_track_names.iloc[i]} by {most_similar_artists.iloc[i]}:')\n",
    "    for j in range(len(feature_names)):\n",
    "        print(f'{feature_names[j]}: {most_similar_features.iloc[i, j]}')\n",
    "    print()  # print an empty line for spacing between each track"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
